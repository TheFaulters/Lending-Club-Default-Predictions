<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Lending Club default predictions by TheFaulters</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Lending Club default predictions</h1>
      <h2 class="project-tagline">A chronicle of our analysis of Lending Club data.</h2>
      <a href="https://github.com/TheFaulters/Lending-Club-Default-Predictions" class="btn">View on GitHub</a>
      <a href="https://github.com/TheFaulters/Lending-Club-Default-Predictions/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/TheFaulters/Lending-Club-Default-Predictions/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="lending-club-default-predictions" class="anchor" href="#lending-club-default-predictions" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Lending Club Default Predictions</h1>

<p><em>Arthur Aguillar, Dwijo Goswami and James Fallon</em><br>
<em>Harvard University</em><br>
<em>CS109A: Introduction to Data Science</em><br>
<em>Final project</em>  </p>

<h2>
<a id="data-exploration" class="anchor" href="#data-exploration" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Data exploration</h2>

<p>Our task was to predict loan defaults using data provided by <a href="https://www.lendingclub.com">Lending Club</a>, a peer to peer lending service. The organization makes de-identified loan <a href="https://www.lendingclub.com/info/download-data.action">data</a> available publicly. </p>

<p>We began by exploring the loan data. We categorized loans into those currently in delinquency or default (risky loans) and those with no payment violations (not risky loans).  </p>

<p>Initially, we wanted to explore some basic relationships. In the first instance, we were interested in how poorly loans had performed based on when they were issued.  </p>

<p><strong>Figure 1:</strong>  </p>

<p><img src="https://thefaulters.github.io/Lending-Club-Default-Predictions/Images/Loans-delinquency-bar.png" alt=""></p>

<p>Additionally, we were interested in whether higher risk borrowers (those with lower grades) consistently had to pay higher interest rates (and whether they indeed defaulted more often). We also wanted to make sure to account for imbalance in the dataset - since most borrowers don't default.  </p>

<p><strong>Figure 2:</strong></p>

<p><img src="https://thefaulters.github.io/Lending-Club-Default-Predictions/Images/Risk.png" alt=""> <img src="https://thefaulters.github.io/Lending-Club-Default-Predictions/Images/Imbalance.png" alt=""></p>

<h2>
<a id="cleaning" class="anchor" href="#cleaning" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Cleaning</h2>

<p>Using all data from 2007 through the second quarter of 2016 resulted in a dataset with 1,119,194 loan observations. The dataset had 111 variables - pieces of information on each borrower ranging from the interest rate on the loan to a personal description or sales pitch describing the purpose of the loan.    </p>

<p>It is clear from Figure 1 above that risky loan rates decrease dramatically for loans that have been active for a shorter period of time. We feared that this could be due to the short duration of those loans relative to their maturity, and that using these to build a predictive model would result in identifying risky borrowers as not risky borrowers. So we dropped all 2016 data, using only data from 2007 through 2015.</p>

<p>To run most of our models, we needed the data to be in numerical format. However, the dataset was full of various datatypes. So our cleaning process mostly consisted of ensuring all numbers were indeed in numerical format, and generating dummy variables for categorical variables like loan grade and state of residence. Following feedback from our TF, we also dropped variables that could only be determined after the loan was issued. For example, delayed payments or late fees.   </p>

<p>After the cleaning process, the final dataset contained 887,440 observations, 216 predictor variables and one binary response variable: a 1 for risky loans and a 0 for safe loans.  </p>

<p><strong>Figure 3: Cleaning</strong><br>
<img src="https://thefaulters.github.io/Lending-Club-Default-Predictions/Images/cleaning_1.png" alt=""><img src="https://thefaulters.github.io/Lending-Club-Default-Predictions/Images/cleaning_2.png" alt=""><br>
<img src="https://thefaulters.github.io/Lending-Club-Default-Predictions/Images/cleaning_3.png" alt=""><img src="https://thefaulters.github.io/Lending-Club-Default-Predictions/Images/cleaning_4.png" alt="">  </p>

<h2>
<a id="modelling" class="anchor" href="#modelling" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Modelling</h2>

<p>Once we cleaned and explored the data, we began testing different models for accuracy in prediction. Our general approach towards testing a model was to use a small sub-sample for optimizing the parameters of the model, and then using these parameters to fit the model on a larger sub-set of the data. The sizes of sub-samples and sub-sets varied in some cases such as Support Vector Classification, due to computational efficiency constraints. We followed this approach to test three different models for binary classification - Random Forests, Logistic Regression and Support Vector Classification.</p>

<h2>
<a id="random-forests" class="anchor" href="#random-forests" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Random forests</h2>

<p>Random Forests is described as an 'ensemble' learning method for classification. Such a learning method runs multiple learning algorithms in order to improve predictive performance over a singular prediction (Rokach). The model generates randomized decision trees, and aggregates the mode prediction across these trees for classification problems. The randomization of the trees reduces the possibilities of overfitting the prediction to the training data.</p>

<p>Random Forests was the basis for our baseline numbers during Milestone 4. However, the results in the final project submission is not strictly comparable to Milestone 4 results, as we made a number of changes to our data and model based on feedback. Most prominently, we removed a number of highly correlated variables in our cleaning exercise, and we are now using balanced class weights to compensate for the imbalanced data.</p>

<p>Despite these changes, our original arguments for using Random Forests in Milestone 4 are still applicable. The model is very efficient (compared to the other models we tested), and has had prior success in predicting loan defaults in P2P platforms (Pandey, J.N.). The model is also particularly good at handling high multidimensionality, as it treats variables in a sequential manner as it goes through the trees.</p>

<p>In our modeling we first optimized Random Forest for number of trees and depth of the trees. We then fitted a larger sub-sample for the most predictive number of trees and depth size. As with all out models, we balanced the class weights to compensate for the unbalanced dataset shown above.  </p>

<p><strong>Figure 4:</strong>  </p>

<p><img src="https://thefaulters.github.io/Lending-Club-Default-Predictions/Images/RF_opt.png" alt=""></p>

<h2>
<a id="logistic-regression" class="anchor" href="#logistic-regression" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Logistic regression</h2>

<p>Logistic Regression is the first model that comes to mind in terms of binary classification. It is a probabilistic model for categorical dependent variables i.e. it uses the input data to predicts the probability of the output category. This model tends to perform better in datasets where the classification problem is linearly separable. Logistic Regression also offers us the opportunity to penalize coefficient predictions.  The L1 and L2 penalties also provide us room to do feature selection and compensate for the high dimensionality of any dataset.</p>

<p>The approach to optimizing the Logistic Regression model was as follows. We first optimized for the penalty parameter using 3 fold cross validation, for both L1 and L2 penalties. Once we had the optimal parameter for each penalty function, we fitted the data on a larger subsample to test for accuracy. The L1 penalty consistently outperformed the L2 penalty. However, in the case of our dataset, we did not find Logistic Regression to perform better than Random Forests both in terms of accuracy or computational efficiency.   </p>

<p><strong>Figure 5: l1 optimization</strong><br>
<img src="https://thefaulters.github.io/Lending-Club-Default-Predictions/Images/l1_opt.png" alt="">  </p>

<p><strong>Figure 6: l2 optimization</strong><br>
<img src="https://thefaulters.github.io/Lending-Club-Default-Predictions/Images/l2_opt.png" alt=""></p>

<h2>
<a id="support-vector-machine" class="anchor" href="#support-vector-machine" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Support vector machine</h2>

<p><strong>Figure 7:</strong>
<img src="https://thefaulters.github.io/Lending-Club-Default-Predictions/Images/svm_opt.png" alt=""></p>

<p>Next, we used a support vector machine to classify loan risk. We chose SVM because our dataset is very large and features a binary response variable. Our approach was guided by James et al pp 344-35 and Hsu et al.  </p>

<p>While we had expected SVM to be more efficient than other models, it was in fact one of the slowest models we attempted. As a result, we tuned with 1% of the dataset (8,874 observations), trained with 5% and validated with 5% (44,372 observations).   </p>

<p>On the guidance of Hsu et al, we tuned for gamma - a parameter specific to the radial kernel - and C - the misclassification parameter. We also scaled the x input to have mean 0 and standard deviation 1. As with our other models, we balanced the class weights to account for the underrepresentation of risky loans in the overall dataset.  </p>

<h1>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results</h1>

<p>One of the most important feedback we received during Milestone 4, was to focus less on the overall accuracy of the prediction and more on the ability of our model to predict loan risk. Ultimately, we care about our models ability to predict a risky loan, which will always be a smaller number of cases in a healthy loan portfolio.</p>

<p>Therefore, in our final results and model selection, we have compared models not on their overall accuracy, but on their ability to predict loan risk. We used two mechanisms to compare their relative performance - a Receiver Operating Curve and a Precision/Recall curve.</p>

<p>A Receiver Operating Curve is perhaps the most intuitive to understand. It represents the trade off between a true positive and a false positive prediction. As any model attempts to identify more 'true' risky loans, it is likely to identify a number of non-risky loans as risky as collateral damage for spreading its net too far. The lower the collateral damage, the better the model. Therefore one can use ROC to understand how efficiently any model is identifying defaults correctly. Most intuitively, this can be understood as the area under the ROC curve. The higher the area under the curve, the more efficiently the model is making the ROC tradeoff.</p>

<p>A Precision/Recall Curve is slightly more complicated. The Precision Rate of any model is the number of 'true' risky loans in its predictions. The Recall Rate on the other hand is the number of correctly identified risky loan from all the 'true' risky loans in the dataset. Much like the ROC, the curve represents a trade off - as a model attempts to identify more of the 'true' risky loans (i.e. increase the Recall Rate), its Precision Rate will decline due to collateral damage. Again, the model which demonstrates the lowest trade off between Precision and Recall is the most effective model.  </p>

<p><strong>Figure 8:</strong><br>
<img src="https://thefaulters.github.io/Lending-Club-Default-Predictions/Images/ROC.png" alt=""><img src="https://thefaulters.github.io/Lending-Club-Default-Predictions/Images/Penalty_Recall.png" alt="">  </p>

<p>In all of our assessments, we consistently find Random Forests to be outperforming all the other models in loan riskiness prediction. When we finally tested our optimized model of choice, we found it can predict ______% of risky loans accurately.  </p>

<h2>
<a id="appendix-sentiment-analysis" class="anchor" href="#appendix-sentiment-analysis" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Appendix: Sentiment analysis</h2>

<p>While we had initially dropped the borrower's description, we wanted to revisit this variable to conduct sentiment analysis. Essentially, we hoped to use the borrower's loan pitch to see if descriptions contained any particular red flags.  </p>

<p>We first performed a visual analysis of the words used more often by risky borrowers and non risky borrowers. It is interesting to observe that the word "card" is the most used by risky borrowers, while the word loan is the most used by non risky borrowers: One simple intuition for that is that risky borrowers are often refinancing their older debts as well as borrowing for consumption reasons, while non risky borrowers apply for loans due to different reasons.  </p>

<p><strong>Figure 9: Risky Borrowers</strong><br>
<img src="https://thefaulters.github.io/Lending-Club-Default-Predictions/Images/risky_borrowerss.png" alt=""></p>

<p><strong>Figure 10: Safe Borrowers</strong><br>
<img src="https://thefaulters.github.io/Lending-Club-Default-Predictions/Images/nrisky_borrowerss.png" alt="">  </p>

<p>We now select our preferred model. We will optimize - by testing distinct values for penalties and performing cross validation - 2 kinds of weighted logistic regressions, one that uses a l1 penalty (analogous to a Lasso, therefore excluding the least explanatory variables by "shrinking" coefficients up to 0), and the other that uses a l2 penalty (with a regulariation parameter analogous to a Ridge, that shrink coeffcients towards zero, but not to the point of excluding coefficients. We also use weighted models due to the imbalances on the response variable. Under the penalties that maximize accuracy, our weighted logistic regression with penalty l1 performs 85.8% of accurate classifications, while our weighted logistic regression with l2 penalty perfroms 75.93% of accurate classifications. However, the model with l2 penalty performs better in the ROC curve, that is, the model is more accurate under the umbalanced class. </p>

<p>Our preferred model therefore performs 75.93% of accurate classifications, with a precision of 86.4% for class 0 and  and 17.5% for class 1. This means that we are performing an accurate classification of a very small percentage of the actual risky loans.    </p>

<p><strong>Figure 11: ROC curve for sentiment analysis</strong><br>
<img src="https://thefaulters.github.io/Lending-Club-Default-Predictions/Images/sent_ROC.png" alt="">  </p>

<p>It is clear from our low accuracy rating for the risky class, as well as the ROC curve above, that this model was not successful compared to our other approaches. If we were to take this further we would explore conducting other sorts of analysis on the descriptions - for example exploring libraries that might help us identify typos or bad grammar. While we could potentially draw more predictive power from such an approach, we will not pursue this approach in the context of this project.  </p>

<h3>
<a id="references" class="anchor" href="#references" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>References</h3>

<p>Ceyhan S, Shi X and Leskovec J (2011). "Dynamics of bidding in a P2P lending service: effects of herding and predicting loan success." <em>Proceedings of the 20th International Conference on the World Wide Web (pp 547-556).</em></p>

<p>Hsu C, Chang C and Lin C (2016). "A Practical Guide to Support Vector Classification." <em>National Taiwan University, Department of Computer Science.</em></p>

<p>Iyer R, Khwaja A, Luttmer E, Shue K (2009) “Screening in New Credit Markets: Can Individual Lenders Infer Borrower Creditworthiness in Peer-to-Peer Lending?” <em>Harvard Kennedy School of Government, Faculty Research Working Papers Series: RWP09-031 (September 2009).</em></p>

<p>James G, Witten D, Hastie T and Tibshirani R (2015). "An Introduction to Statistical Learning with Applications in R." <em>New York: Springer.</em></p>

<p><a href="https://www.lendingclub.com/info/download-data.action">Lending Club Statistics.</a> <em>Lending Club.</em></p>

<p>Pander J and Srinivasan M (2011). <a href="http://cs229.stanford.edu/proj2011/PandeySrinivasan-PredictingProbabilityOfLoanDefault.pdf">"Predicting Probability of Loan Default."</a> <em>Stanford University, CS229 Project report.</em> </p>

<p>Rokach, Lior. "Ensemble-based classifiers." <em>Artificial Intelligence Review 33.1-2 (2010): 1-39</em></p>

<p>Tsai K, Ramiah S and Singh S (2014). <a href="http://cs229.stanford.edu/proj2014/Kevin%20Tsai,Sivagami%20Ramiah,Sudhanshu%20Singh,Peer%20Lending%20Risk%20Predictor.pdf">"Peer Lending Risk Predictor"</a> <em>Stanford University, CS229 Project Report.</em></p>

<h3>
<a id="acknowledgements" class="anchor" href="#acknowledgements" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Acknowledgements</h3>

<p>We would like to thank our Teaching Fellow Qing Zhao for her guidance and support on this project. We would also like to thank the teaching staff of CS109a for their feedback and suggestions.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/TheFaulters/Lending-Club-Default-Predictions">Lending Club default predictions</a> is maintained by <a href="https://github.com/TheFaulters">TheFaulters</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
